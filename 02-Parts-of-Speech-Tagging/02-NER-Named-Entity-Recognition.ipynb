{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd695009-eab6-4e49-94a2-38fc8a779072",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca80a814-a65d-486c-a25c-77edf5bf3d72",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Named Entity Recognition (NER)\n",
    "spaCy has an **'ner'** pipeline component that identifies token spans fitting a predetermined set of named entities. These are available as the `ents` property of a `Doc` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5db64a5-e043-4d5f-a6fb-40e3cb86d460",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.9/site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy) (58.0.4)\n",
      "Collecting tqdm<5.0.0,>=4.38.0\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Using cached pydantic-1.10.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (491 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.9-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.9/site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: jinja2 in /databricks/python3/lib/python3.9/site-packages (from spacy) (2.11.3)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Using cached typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Using cached thinc-8.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /databricks/python3/lib/python3.9/site-packages (from spacy) (1.20.3)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Using cached pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Collecting typing-extensions>=4.2.0\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /databricks/python3/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /databricks/python3/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: typing-extensions, catalogue, srsly, pydantic, murmurhash, cymem, wasabi, typer, smart-open, preshed, confection, blis, tqdm, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca\n",
      "    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.5 smart-open-6.3.0 spacy-3.5.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.8 tqdm-4.65.0 typer-0.7.0 typing-extensions-4.5.0 wasabi-1.1.1\n",
      "Python interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "305da12a-3ac2-4702-8fe6-ae0b315f49ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\n",
      "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz (13.7 MB)\n",
      "Collecting spacy<3.1.0,>=3.0.0\n",
      "  Using cached spacy-3.0.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.26.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (58.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.65.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.9)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (21.0)\n",
      "Requirement already satisfied: jinja2 in /databricks/python3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Using cached typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.3\n",
      "  Using cached thinc-8.0.17-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (668 kB)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.7)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /databricks/python3/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.20.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.12)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (6.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.10.8)\n",
      "Collecting click<7.2.0,>=7.1.1\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /databricks/python3/lib/python3.9/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-3.0.0-py3-none-any.whl size=13704318 sha256=91cc05127b426a432aaed20b3d8703eb83a06bb29e95f094c9fdb5d6989d8d7a\n",
      "  Stored in directory: /root/.cache/pip/wheels/88/16/62/706709a80d48c983fffc44547114a933c464cd032e19378fb2\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: click, wasabi, typer, pydantic, thinc, spacy, en-core-web-sm\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.3\n",
      "    Not uninstalling click at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-aa0c0f40-810a-4537-97ed-fa43436a96ca\n",
      "    Can't uninstall 'click'. No files were found to uninstall.\n",
      "  Attempting uninstall: wasabi\n",
      "    Found existing installation: wasabi 1.1.1\n",
      "    Uninstalling wasabi-1.1.1:\n",
      "      Successfully uninstalled wasabi-1.1.1\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.7.0\n",
      "    Uninstalling typer-0.7.0:\n",
      "      Successfully uninstalled typer-0.7.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.5\n",
      "    Uninstalling pydantic-1.10.5:\n",
      "      Successfully uninstalled pydantic-1.10.5\n",
      "  Attempting uninstall: thinc\n",
      "    Found existing installation: thinc 8.1.8\n",
      "    Uninstalling thinc-8.1.8:\n",
      "      Successfully uninstalled thinc-8.1.8\n",
      "  Attempting uninstall: spacy\n",
      "    Found existing installation: spacy 3.5.0\n",
      "    Uninstalling spacy-3.5.0:\n",
      "      Successfully uninstalled spacy-3.5.0\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "black 22.3.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible.\n",
      "Successfully installed click-7.1.2 en-core-web-sm-3.0.0 pydantic-1.8.2 spacy-3.0.9 thinc-8.0.17 typer-0.3.2 wasabi-0.10.1\n",
      "Python interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install \"https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13a74ce0-8bca-4a78-abc7-a1edbf6d7434",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cadd3a43-02ae-4995-a6c7-74402e9023fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write a function to display basic entity info:\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9701b8a0-2c4f-427a-9fa1-1b3c2ea6f84c",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington, DC - GPE - Countries, cities, states\n",
      "next May - DATE - Absolute or relative dates or periods\n",
      "the Washington Monument - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'May I go to Washington, DC next May to see the Washington Monument?')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6d3830c-d3ef-41d6-b82b-8434ff51fe08",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Here we see tokens combine to form the entities `Washington, DC`, `next May` and `the Washington Monument`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed34ff9c-cbeb-4d3c-8e98-03352a8bf0e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Entity annotations\n",
    "`Doc.ents` are token spans with their own set of annotations.\n",
    "<table>\n",
    "<tr><td>`ent.text`</td><td>The original entity text</td></tr>\n",
    "<tr><td>`ent.label`</td><td>The entity type's hash value</td></tr>\n",
    "<tr><td>`ent.label_`</td><td>The entity type's string description</td></tr>\n",
    "<tr><td>`ent.start`</td><td>The token span's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end`</td><td>The token span's *stop* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.start_char`</td><td>The entity text's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end_char`</td><td>The entity text's *stop* index position in the Doc</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fa11851-9994-4ba8-afc7-1e3118e19a34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 dollars 4 6 20 31 MONEY\n",
      "Microsoft 11 12 53 62 ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Can I please borrow 500 dollars from you to buy some Microsoft stock?')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start, ent.end, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78099bd8-4087-4a85-85a2-a8139340cea7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## NER Tags\n",
    "Tags are accessible through the `.label_` property of an entity.\n",
    "<table>\n",
    "<tr><th>TYPE</th><th>DESCRIPTION</th><th>EXAMPLE</th></tr>\n",
    "<tr><td>`PERSON`</td><td>People, including fictional.</td><td>*Fred Flintstone*</td></tr>\n",
    "<tr><td>`NORP`</td><td>Nationalities or religious or political groups.</td><td>*The Republican Party*</td></tr>\n",
    "<tr><td>`FAC`</td><td>Buildings, airports, highways, bridges, etc.</td><td>*Logan International Airport, The Golden Gate*</td></tr>\n",
    "<tr><td>`ORG`</td><td>Companies, agencies, institutions, etc.</td><td>*Microsoft, FBI, MIT*</td></tr>\n",
    "<tr><td>`GPE`</td><td>Countries, cities, states.</td><td>*France, UAR, Chicago, Idaho*</td></tr>\n",
    "<tr><td>`LOC`</td><td>Non-GPE locations, mountain ranges, bodies of water.</td><td>*Europe, Nile River, Midwest*</td></tr>\n",
    "<tr><td>`PRODUCT`</td><td>Objects, vehicles, foods, etc. (Not services.)</td><td>*Formula 1*</td></tr>\n",
    "<tr><td>`EVENT`</td><td>Named hurricanes, battles, wars, sports events, etc.</td><td>*Olympic Games*</td></tr>\n",
    "<tr><td>`WORK_OF_ART`</td><td>Titles of books, songs, etc.</td><td>*The Mona Lisa*</td></tr>\n",
    "<tr><td>`LAW`</td><td>Named documents made into laws.</td><td>*Roe v. Wade*</td></tr>\n",
    "<tr><td>`LANGUAGE`</td><td>Any named language.</td><td>*English*</td></tr>\n",
    "<tr><td>`DATE`</td><td>Absolute or relative dates or periods.</td><td>*20 July 1969*</td></tr>\n",
    "<tr><td>`TIME`</td><td>Times smaller than a day.</td><td>*Four hours*</td></tr>\n",
    "<tr><td>`PERCENT`</td><td>Percentage, including \"%\".</td><td>*Eighty percent*</td></tr>\n",
    "<tr><td>`MONEY`</td><td>Monetary values, including unit.</td><td>*Twenty Cents*</td></tr>\n",
    "<tr><td>`QUANTITY`</td><td>Measurements, as of weight or distance.</td><td>*Several kilometers, 55kg*</td></tr>\n",
    "<tr><td>`ORDINAL`</td><td>\"first\", \"second\", etc.</td><td>*9th, Ninth*</td></tr>\n",
    "<tr><td>`CARDINAL`</td><td>Numerals that do not fall under another type.</td><td>*2, Two, Fifty-two*</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a4317a9-aadc-453b-b410-b5c2a370d46a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "___\n",
    "## Adding a Named Entity to a Span\n",
    "Normally we would have spaCy build a library of named entities by training it on several samples of text.<br>In this case, we only want to add one value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19d1ad15-5352-4686-bdc7-de0819cab5a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chengdu - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Tesla to build a Chengdu factory for $6 million')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f830c5c0-f463-4875-b442-82e913701831",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<font color=green>Right now, spaCy does not recognize \"Tesla\" as a company.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fed5f91b-d563-4811-aceb-de9e0f8ca1e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "# Get the hash value of the ORG entity label\n",
    "ORG = doc.vocab.strings[u'ORG']  \n",
    "\n",
    "# Create a Span for the new entity\n",
    "new_ent = Span(doc, 0, 1, label=ORG)\n",
    "\n",
    "# Add the entity to the existing Doc object\n",
    "doc.ents = list(doc.ents) + [new_ent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79a5b70b-1b13-4236-a7cd-d45d5ee6fcb5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<font color=green>In the code above, the arguments passed to `Span()` are:</font>\n",
    "-  `doc` - the name of the Doc object\n",
    "-  `0` - the *start* index position of the span\n",
    "-  `1` - the *stop* index position (exclusive)\n",
    "-  `label=ORG` - the label assigned to our entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5292e15-d229-4aa9-9bd8-d6166ee182d6",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla - ORG - Companies, agencies, institutions, etc.\n",
      "Chengdu - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d39d180-6570-44d1-b2b7-4b0b35f27cda",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "___\n",
    "## Adding Named Entities to All Matching Spans\n",
    "What if we want to tag *all* occurrences of \"Tesla\"? In this section we show how to use the PhraseMatcher to identify a series of spans in the Doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab1de9e0-4c90-4fd0-8bc7-ae9031bd1388",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first - ORDINAL - \"first\", \"second\", etc.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Our company plans to introduce a new vacuum cleaner. '\n",
    "          u'If successful, the vacuum cleaner will be our first product.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b612a36d-9bc0-4b7f-92e8-6ab86d3b4183",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[14]: 'Our company plans to introduce a new vacuum cleaner. If successful, the vacuum cleaner will be our first product.'"
     ]
    }
   ],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9073725d-94cd-46f4-9297-9365ece66ece",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import PhraseMatcher and create a matcher object:\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "968a33eb-41c5-4b82-bc52-3e844cdee577",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the desired phrase patterns:\n",
    "phrase_list = ['vacuum cleaner', 'vacuum-cleaner']\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cad458e9-e9a3-453e-9bbf-73114530607b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[17]: [(2689272359382549672, 7, 9), (2689272359382549672, 14, 16)]"
     ]
    }
   ],
   "source": [
    "# Apply the patterns to our matcher object:\n",
    "matcher.add('newproduct', None, *phrase_patterns)\n",
    "\n",
    "# Apply the matcher to our Doc object:\n",
    "matches = matcher(doc)\n",
    "\n",
    "# See what matches occur:\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69cd8bbe-39ce-4996-9e72-6b643103c344",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Here we create Spans from each match, and create named entities from them:\n",
    "from spacy.tokens import Span\n",
    "\n",
    "PROD = doc.vocab.strings[u'PRODUCT']\n",
    "\n",
    "new_ents = [Span(doc, match[1],match[2],label=PROD) for match in matches]\n",
    "\n",
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e6c0d62-380b-4134-91be-cfe8864ec725",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "vacuum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "first - ORDINAL - \"first\", \"second\", etc.\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ead140a-5ddb-41b6-86d8-5aa4d2100354",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "___\n",
    "## Counting Entities\n",
    "While spaCy may not have a built-in tool for counting entities, we can pass a conditional statement into a list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37141ef7-8733-4c00-89a2-a1de687d4a9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50 - MONEY - Monetary values, including unit\n",
      "five dollars - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Originally priced at $29.50, the sweater was marked down to five dollars.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47d0a017-20a4-467f-a08d-78839f08585d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[21]: 2"
     ]
    }
   ],
   "source": [
    "len([ent for ent in doc.ents if ent.label_=='MONEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26a42e1c-4c4a-4394-a3c1-d2656875a23f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## <font color=blue>Problem with Line Breaks</font>\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"margin: 20px\">There's a <a href='https://github.com/explosion/spaCy/issues/1717'>known issue</a> with <strong>spaCy v2.0.12</strong> where some linebreaks are interpreted as `GPE` entities:</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eccc6a4d-98e8-4e2f-8713-33303d369486",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[22]: '3.0.9'"
     ]
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e51bda31-6558-4a1e-9d0b-63828f950536",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50 - MONEY - Monetary values, including unit\n",
      "five dollars - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Originally priced at $29.50,\\nthe sweater was marked down to five dollars.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "631e0a42-9bd1-4cfc-af16-243eba33e42b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### <font color=blue>However, there is a simple fix that can be added to the nlp pipeline:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52a6935d-1274-49fb-a602-d497ba3e8e29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Quick function to remove ents formed on whitespace:\n",
    "def remove_whitespace_entities(doc):\n",
    "    doc.ents = [e for e in doc.ents if not e.text.isspace()]\n",
    "    return doc\n",
    "\n",
    "# Insert this into the pipeline AFTER the ner component:\n",
    "nlp.add_pipe(remove_whitespace_entities, after='ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3e69eaf-d419-41a2-ac99-4103a16dd04b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50 - MONEY - Monetary values, including unit\n",
      "five dollars - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "# Rerun nlp on the text above, and show ents:\n",
    "doc = nlp(u'Originally priced at $29.50,\\nthe sweater was marked down to five dollars.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37ca12ea-2f6f-4fc3-a589-babe9beeb342",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For more on **Named Entity Recognition** visit https://spacy.io/usage/linguistic-features#101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24e536eb-8f6b-41a8-9f74-a2b2ee264dac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "___\n",
    "## Noun Chunks\n",
    "`Doc.noun_chunks` are *base noun phrases*: token spans that include the noun and words describing the noun. Noun chunks cannot be nested, cannot overlap, and do not involve prepositional phrases or relative clauses.<br>\n",
    "Where `Doc.ents` rely on the **ner** pipeline component, `Doc.noun_chunks` are provided by the **parser**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d89867f-c5bc-4b03-bfae-8d27b07a720f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### `noun_chunks` components:\n",
    "<table>\n",
    "<tr><td>`.text`</td><td>The original noun chunk text.</td></tr>\n",
    "<tr><td>`.root.text`</td><td>The original text of the word connecting the noun chunk to the rest of the parse.</td></tr>\n",
    "<tr><td>`.root.dep_`</td><td>Dependency relation connecting the root to its head.</td></tr>\n",
    "<tr><td>`.root.head.text`</td><td>The text of the root token's head.</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09d41bc9-2c79-4747-9bbf-b0f921e9855f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars - cars - nsubj - shift\n",
      "insurance liability - liability - dobj - shift\n",
      "manufacturers - manufacturers - pobj - toward\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text+' - '+chunk.root.text+' - '+chunk.root.dep_+' - '+chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01c978b7-ba77-45bb-8196-d926597cdde4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### `Doc.noun_chunks` is a  generator function\n",
    "Previously we mentioned that `Doc` objects do not retain a list of sentences, but they're available through the `Doc.sents` generator.<br>It's the same with `Doc.noun_chunks` - lists can be created if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca906336-4a52-4601-8c77-b8b49bbfb270",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
       "\u001b[1;32m<ipython-input-21-8b52b37c204e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
       "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[0m\n",
       "\u001b[1;31mTypeError\u001b[0m: object of type 'generator' has no len()"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n\u001b[1;32m<ipython-input-21-8b52b37c204e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\n\u001b[1;31mTypeError\u001b[0m: object of type 'generator' has no len()",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: object of type 'generator' has no len()",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4220bef2-6e93-4755-ad14-59caac7dbfec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": {
        "text/plain": [
         "3"
        ]
       },
       "datasetInfos": [],
       "executionCount": 22,
       "metadata": {},
       "removedWidgets": [],
       "type": "mimeBundle"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(doc.noun_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dc89eb2-ce9e-4660-91e5-eacb35512bed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For more on **noun_chunks** visit https://spacy.io/usage/linguistic-features#noun-chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8089aecc-a826-4a9f-8259-f351aa5fcbeb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Great! Now you should be more familiar with both named entities and noun chunks. In the next section we revisit the NER visualizer.\n",
    "## Next up: Visualizing NER"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02-NER-Named-Entity-Recognition",
   "notebookOrigID": 1919818433381626,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
